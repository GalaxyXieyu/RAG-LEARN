# 第一步：数据清洗与预处理 🔧

## 模块概述

本模块介绍RAG系统中最基础但最重要的一步 - **数据清洗与预处理**。正如"Garbage in, Garbage out"所说，输入数据的质量直接决定了RAG系统的效果。

## 学习目标

- ✅ 理解为什么数据预处理如此重要
- ✅ 掌握处理图片、表格等复杂格式的方法
- ✅ 学会数据清洗和格式标准化技巧
- ✅ 了解如何使用多模态模型提取图片信息

## 核心内容

### 1. 输入优化原则

#### 内容精简
- 只导入会被提问到的资料
- 避免冗余数据降低检索准确度
- 定期清理过时或无用的内容

#### 内容准确
- 确保描述中的名词、动词、形容词无歧义
- 避免矛盾的表述
- 统一术语和概念

**案例**：
```
❌ 错误示例：
文档A：公司要招收211和985院校学生
文档B：支持双非院校学生

✅ 正确做法：
统一招聘标准，或明确不同项目的不同要求
```

### 2. 格式标准化

#### 图片处理
RAG主要基于文本检索，图片无法直接检索。解决方案：

- **多模态提取**：使用GPT-4V、Claude等多模态模型描述图片内容
- **OCR识别**：对于包含文字的图片，使用OCR提取文本
- **结构化描述**：将图片转化为结构化的文本描述

**代码示例**：
```python
# 使用多模态模型描述图片
from langchain_openai import AzureChatOpenAI

llm = AzureChatOpenAI(model="gpt-4o")
image_description = llm.invoke([
    {"type": "text", "text": "请详细描述这张图片的内容"},
    {"type": "image_url", "image_url": {"url": image_url}}
])
```

#### 表格处理
表格数据需要转化为可检索的格式：

- **Markdown格式**：保留表格结构
- **自然语言描述**：将每行数据转化为一句话
- **结构化提取**：提取关键字段和数值

**转化示例**：
```
原始表格：
| 产品 | 价格 | 库存 |
|------|------|------|
| A    | 100  | 50   |

转化为：
"产品A的价格是100元，当前库存50件。"
```

### 3. 推荐工具

#### OmniParse
一站式文档解析工具，支持：
- PDF、Word、Excel等多种格式
- 图片、表格、语音、视频内容提取
- 可视化界面，方便查看和优化

**特点**：
- 开源免费
- 支持多种文件类型
- 可视化效果展示
- API接口方便集成

项目地址：[OmniParse GitHub](https://github.com/adithya-s-k/omniparse)

## 实践练习

### 📓 Notebook：data_process.ipynb

本模块的Jupyter Notebook包含以下内容：

1. **PDF文档解析**
   - 使用Unstructured库提取内容
   - 识别文本、图片、表格元素

2. **图片内容提取**
   - 使用多模态模型描述图片
   - OCR文字识别

3. **表格数据处理**
   - 表格转Markdown
   - 表格转自然语言

4. **数据清洗**
   - 去除无效字符
   - 统一格式
   - 分块策略

### 运行步骤

```bash
# 1. 确保已安装依赖
pip install -r ../requirements.txt

# 2. 启动Jupyter
jupyter notebook data_process.ipynb

# 3. 按顺序运行每个单元格
```

## 常见问题

### Q1: 图片提取后检索效果不好怎么办？
**A**: 尝试以下方法：
- 优化图片描述的Prompt，要求更详细的描述
- 同时保存原图URL，在必要时显示原图
- 使用多个模型交叉验证描述的准确性

### Q2: 表格数据量大，如何处理？
**A**: 
- 将大表格拆分成多个小块
- 每一行或相关的几行作为一个独立文档
- 保留表头信息，确保上下文完整

### Q3: 如何判断数据清洗是否到位？
**A**: 
- 抽样检查处理后的文本质量
- 测试典型问题的检索效果
- 对比处理前后的检索准确率

## 下一步

完成数据清洗后，继续学习：

➡️ [第二步：数据检索技术](../02_data_retriever/README.md)

---

💡 **提示**：数据预处理是RAG系统的基础，值得花时间做好。好的数据预处理能让后续的检索和生成事半功倍！

