"""å…³ç³»æ•°æ®åº“å­˜å‚¨"""

import logging
import hashlib
from typing import Dict, List, Optional
from datetime import datetime

from app.db.session import get_sz_pm_db

logger = logging.getLogger(__name__)


class DBStorage:
    """å…³ç³»æ•°æ®åº“å­˜å‚¨ç±»
    
    è´Ÿè´£å®ä½“å’Œå…³ç³»çš„å…³ç³»æ•°æ®åº“å­˜å‚¨ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®åº“å­˜å‚¨"""
        pass

    async def save_entity(self, entity_data: Dict):
        """ä¿å­˜å®ä½“åˆ°å…³ç³»æ•°æ®åº“"""
        try:
            async with get_sz_pm_db() as db:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåªç”¨entity_nameï¼‰
                check_sql = """
                    SELECT ENTITY_ID, DESCRIPTION FROM FAI_SZ.KG_ENTITIES 
                    WHERE ENTITY_NAME = ?
                """
                cursor = await db.execute(check_sql, [entity_data["entity_name"]])
                existing = cursor.fetchone()

                if existing:
                    # åˆå¹¶æè¿°ï¼ˆLightRAGæ–¹å¼ï¼‰
                    existing_id, existing_desc = existing
                    new_desc = entity_data["description"] or ""

                    # ä½¿ç”¨åˆ†éš”ç¬¦åˆå¹¶
                    if existing_desc and new_desc and existing_desc != new_desc:
                        merged_desc = f"{existing_desc};{new_desc}"
                    else:
                        merged_desc = existing_desc or new_desc

                    update_sql = """
                        UPDATE FAI_SZ.KG_ENTITIES 
                        SET DESCRIPTION = ?, ENTITY_TYPE = ?, DOCUMENT_ID = ?, UPDATED_AT = ? 
                        WHERE ENTITY_ID = ?
                    """
                    await db.execute(
                        update_sql,
                        [
                            merged_desc,
                            entity_data["entity_type"],
                            entity_data["document_id"],
                            self._get_current_timestamp(),
                            existing_id,
                        ],
                    )
                    logger.info(f"ğŸ”„ åˆå¹¶å®ä½“: {entity_data['entity_name']}")
                else:
                    # æ–°å¢å®ä½“ - ç”Ÿæˆç¨³å®šID
                    entity_id = self._generate_entity_id(entity_data["entity_name"])
                    insert_sql = """
                        INSERT INTO FAI_SZ.KG_ENTITIES 
                        (ENTITY_ID, ENTITY_NAME, ENTITY_TYPE, DESCRIPTION, DOCUMENT_ID, CREATED_AT, UPDATED_AT)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """
                    current_time = self._get_current_timestamp()
                    await db.execute(
                        insert_sql,
                        [
                            entity_id,
                            entity_data["entity_name"],
                            entity_data["entity_type"],
                            entity_data["description"],
                            entity_data["document_id"],
                            current_time,
                            current_time,
                        ],
                    )
                    logger.info(
                        f"â• æ–°å¢å®ä½“: {entity_data['entity_name']} (ID: {entity_id})"
                    )

                await db.commit()

        except Exception as e:
            logger.error(f"ä¿å­˜å®ä½“å¤±è´¥: {str(e)}")
            raise

    async def save_relation(self, relation_data: Dict):
        """ä¿å­˜å…³ç³»åˆ°å…³ç³»æ•°æ®åº“"""
        try:
            async with get_sz_pm_db() as db:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºå®ä½“å¯¹å’Œç±»å‹ï¼‰
                check_sql = """
                    SELECT RELATION_ID, DESCRIPTION, KEYWORDS, WEIGHT FROM FAI_SZ.KG_RELATIONS 
                    WHERE SOURCE_ENTITY = ? AND TARGET_ENTITY = ? AND RELATION_TYPE = ?
                """
                cursor = await db.execute(
                    check_sql,
                    [
                        relation_data["source_entity"],
                        relation_data["target_entity"],
                        relation_data["relation_type"],
                    ],
                )
                existing = cursor.fetchone()

                if existing:
                    # åˆå¹¶å…³ç³»ä¿¡æ¯
                    existing_id, existing_desc, existing_keywords, existing_weight = (
                        existing
                    )

                    # åˆå¹¶æè¿°
                    new_desc = relation_data["description"] or ""
                    if existing_desc and new_desc and existing_desc != new_desc:
                        merged_desc = f"{existing_desc};{new_desc}"
                    else:
                        merged_desc = existing_desc or new_desc

                    # åˆå¹¶å…³é”®è¯
                    existing_kw = existing_keywords or ""
                    new_kw = relation_data.get("keywords", "") or ""
                    merged_keywords = self._merge_keywords(existing_kw, new_kw)

                    # æƒé‡ç›¸åŠ 
                    merged_weight = (existing_weight or 1.0) + (
                        relation_data.get("weight", 1.0)
                    )

                    update_sql = """
                        UPDATE FAI_SZ.KG_RELATIONS 
                        SET DESCRIPTION = ?, KEYWORDS = ?, WEIGHT = ?, DOCUMENT_ID = ?, UPDATED_AT = ? 
                        WHERE RELATION_ID = ?
                    """
                    await db.execute(
                        update_sql,
                        [
                            merged_desc,
                            merged_keywords,
                            merged_weight,
                            relation_data["document_id"],
                            self._get_current_timestamp(),
                            existing_id,
                        ],
                    )
                    logger.info(
                        f"ğŸ”„ åˆå¹¶å…³ç³»: {relation_data['source_entity']} -> {relation_data['target_entity']}"
                    )
                else:
                    # æ–°å¢å…³ç³» - ç”Ÿæˆç¨³å®šID
                    relation_id = self._generate_relation_id(
                        relation_data["source_entity"],
                        relation_data["target_entity"],
                        relation_data["relation_type"],
                    )
                    insert_sql = """
                        INSERT INTO FAI_SZ.KG_RELATIONS 
                        (RELATION_ID, SOURCE_ENTITY, TARGET_ENTITY, RELATION_TYPE, DESCRIPTION, KEYWORDS, WEIGHT, DOCUMENT_ID, CREATED_AT, UPDATED_AT)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """
                    current_time = self._get_current_timestamp()
                    await db.execute(
                        insert_sql,
                        [
                            relation_id,
                            relation_data["source_entity"],
                            relation_data["target_entity"],
                            relation_data["relation_type"],
                            relation_data["description"],
                            relation_data.get("keywords", ""),
                            relation_data.get("weight", 1.0),
                            relation_data["document_id"],
                            current_time,
                            current_time,
                        ],
                    )
                    logger.info(
                        f"â• æ–°å¢å…³ç³»: {relation_data['source_entity']} -> {relation_data['target_entity']} (ID: {relation_id})"
                    )

                await db.commit()

        except Exception as e:
            logger.error(f"ä¿å­˜å…³ç³»å¤±è´¥: {str(e)}")
            raise

    async def init_kg_metadata(self, document_id: int):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±å…ƒæ•°æ®"""
        try:
            async with get_sz_pm_db() as db:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                check_sql = (
                    "SELECT COUNT(*) FROM FAI_SZ.KG_METADATA WHERE DOCUMENT_ID = ?"
                )
                cursor = await db.execute(check_sql, [document_id])
                result = cursor.fetchone()
                exists = result[0] > 0 if result else False

                if not exists:
                    # åˆ›å»ºæ–°çš„å…ƒæ•°æ®è®°å½•
                    insert_sql = """
                        INSERT INTO FAI_SZ.KG_METADATA (DOCUMENT_ID, NAMESPACE, STATUS, ENTITY_COUNT, RELATION_COUNT, CREATED_AT, UPDATED_AT)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """
                    current_time = self._get_current_timestamp()
                    await db.execute(
                        insert_sql,
                        [
                            document_id,
                            f"doc_{document_id}",
                            "processing",
                            0,
                            0,
                            current_time,
                            current_time,
                        ],
                    )
                    await db.commit()

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            raise

    async def update_kg_metadata(
        self, document_id: int, entity_count: int, relation_count: int, status: str
    ):
        """æ›´æ–°çŸ¥è¯†å›¾è°±å…ƒæ•°æ®"""
        try:
            async with get_sz_pm_db() as db:
                update_sql = """
                    UPDATE FAI_SZ.KG_METADATA 
                    SET ENTITY_COUNT = ?, RELATION_COUNT = ?, STATUS = ?, UPDATED_AT = ?
                    WHERE DOCUMENT_ID = ?
                """
                current_time = self._get_current_timestamp()
                cursor = await db.execute(
                    update_sql,
                    [entity_count, relation_count, status, current_time, document_id],
                )
                await db.commit()

                # æ£€æŸ¥æ˜¯å¦æ›´æ–°æˆåŠŸ
                if cursor.rowcount > 0:
                    logger.info(
                        f"æ›´æ–°æ–‡æ¡£ {document_id} çš„å…ƒæ•°æ®: å®ä½“={entity_count}, å…³ç³»={relation_count}, çŠ¶æ€={status}"
                    )
                else:
                    logger.warning(f"æ–‡æ¡£ {document_id} çš„å…ƒæ•°æ®è®°å½•ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°")

        except Exception as e:
            logger.error(f"æ›´æ–°å…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            raise

    async def query_entities_by_document(self, document_id: int) -> List[Dict]:
        """æŸ¥è¯¢æ–‡æ¡£çš„æ‰€æœ‰å®ä½“"""
        try:
            async with get_sz_pm_db() as db:
                entity_sql = """
                    SELECT ENTITY_ID, ENTITY_NAME, ENTITY_TYPE, DESCRIPTION, DOCUMENT_ID, CREATED_AT, UPDATED_AT 
                    FROM FAI_SZ.KG_ENTITIES 
                    WHERE DOCUMENT_ID = ?
                """
                cursor = await db.execute(entity_sql, [document_id])
                entity_records = cursor.fetchall()

                result = []
                for record in entity_records:
                    result.append(
                        {
                            "entity_id": record[0],
                            "entity_name": record[1],
                            "entity_type": record[2],
                            "description": record[3],
                            "document_id": record[4],
                            "created_at": record[5],
                            "updated_at": record[6],
                        }
                    )

                logger.info(f"æŸ¥è¯¢åˆ°æ–‡æ¡£ {document_id} çš„ {len(result)} ä¸ªå®ä½“")
                return result

        except Exception as e:
            logger.error(f"æŸ¥è¯¢å®ä½“æ—¶å‡ºé”™: {str(e)}")
            return []

    async def query_relations_by_document(self, document_id: int) -> List[Dict]:
        """æŸ¥è¯¢æ–‡æ¡£çš„æ‰€æœ‰å…³ç³»"""
        try:
            async with get_sz_pm_db() as db:
                relation_sql = """
                    SELECT RELATION_ID, SOURCE_ENTITY, TARGET_ENTITY, RELATION_TYPE, DESCRIPTION, KEYWORDS, WEIGHT, DOCUMENT_ID, CREATED_AT, UPDATED_AT 
                    FROM FAI_SZ.KG_RELATIONS 
                    WHERE DOCUMENT_ID = ?
                """
                cursor = await db.execute(relation_sql, [document_id])
                relation_records = cursor.fetchall()

                result = []
                for record in relation_records:
                    result.append(
                        {
                            "relation_id": record[0],
                            "source_entity": record[1],
                            "target_entity": record[2],
                            "relation_type": record[3],
                            "description": record[4],
                            "keywords": record[5],
                            "weight": record[6],
                            "document_id": record[7],
                            "created_at": record[8],
                            "updated_at": record[9],
                        }
                    )

                logger.info(f"æŸ¥è¯¢åˆ°æ–‡æ¡£ {document_id} çš„ {len(result)} ä¸ªå…³ç³»")
                return result

        except Exception as e:
            logger.error(f"æŸ¥è¯¢å…³ç³»æ—¶å‡ºé”™: {str(e)}")
            return []

    def _generate_entity_id(self, entity_name: str) -> str:
        """ç”Ÿæˆç¨³å®šçš„å®ä½“ID"""
        return f"ent-{hashlib.md5(entity_name.encode('utf-8')).hexdigest()[:16]}"

    def _generate_relation_id(
        self, source: str, target: str, relation_type: str = "RELATED_TO"
    ) -> str:
        """ç”Ÿæˆç¨³å®šçš„å…³ç³»ID"""
        content = f"{source}|{target}|{relation_type}"
        return f"rel-{hashlib.md5(content.encode('utf-8')).hexdigest()[:16]}"

    def _merge_keywords(self, existing_kw: str, new_kw: str) -> str:
        """å…³é”®è¯åˆå¹¶ - å»é‡æ’åº"""
        if not existing_kw:
            return new_kw
        if not new_kw:
            return existing_kw

        # å»é‡åˆå¹¶
        all_keywords = set()
        for kw in (existing_kw + "," + new_kw).split(","):
            kw = kw.strip()
            if kw:
                all_keywords.add(kw)

        return ",".join(sorted(all_keywords))

    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´çš„TIMESTAMPæ ¼å¼å­—ç¬¦ä¸²"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

